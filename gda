#!/usr/bin/env python3
"""
Wrapper script for running GDA
"""
# MIT License
# 
# Copyright (c) 2020-2021 Genome Research Ltd.
# 
# Author: Eerik Aunin (ea10@sanger.ac.uk)
# 
# This file is a part of the Genome Decomposition Analysis (GDA) pipeline.
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import argparse
import sys
import os
feature_extraction_scripts_path = os.path.join(os.path.dirname(os.path.realpath(__file__))) + "/feature_extraction"
sys.path.insert(1, feature_extraction_scripts_path)
import general_purpose_functions as gpf
from datetime import datetime
from shutil import which
from decomposition_gc_skew_repeats_sliding_window import validate_custom_telomeric_seq


def assign_pipeline_run_folder_name():
    """
    Automatically assigns a name for the folder for running the feature extraction pipeline
    """
    current_working_directory = os.getcwd()
    current_date = datetime.today().strftime("%Y%m%d")
    run_folder_name_assigned = False
    for i in range(1, 100000):
        pipeline_run_folder = ""
        if i == 1:
            pipeline_run_folder = current_working_directory + "/" + current_date + "_gda_pipeline_run"
        else:
            pipeline_run_folder = current_working_directory + "/" + current_date + "_gda_pipeline_run_{}".format(i)
        if os.path.isdir(pipeline_run_folder) == True:
            pipeline_run_folder_files = os.listdir(pipeline_run_folder)
            if len(pipeline_run_folder_files) == 0:
                run_folder_name_assigned = True
                break
        elif os.path.isdir(pipeline_run_folder) == False:
            run_folder_name_assigned = True
            break
    if run_folder_name_assigned == False:
        sys.stderr.write("Failed to automatically assign a name for the feature extraction pipeline run folder\n")
        sys.exit(1)
    return pipeline_run_folder


def load_param_descriptions(nextflow_param_descriptions_path):
    """
    Loads Nextflow parameter descriptions from a file into a dictionary
    """
    params_dict = dict()
    params_data = gpf.l(nextflow_param_descriptions_path)
    for line in params_data[1:len(params_data)]:
        split_line = line.split(",")
        param_name = split_line[0]
        param_type = split_line[1]
        param_description = split_line[2]
        params_dict[param_name] = {"type": param_type, "description": param_description}
    return params_dict


def write_nextflow_config_file(args, out_path):
    """
    Takes command line arguments that specify the parameters for the GDA Nextflow run and writes a Nextflow config file based on the argument values
    """
    current_script_folder = os.path.abspath(os.path.dirname(__file__))
    nextflow_param_descriptions_path = current_script_folder + "/feature_extraction/gda_nextflow_param_descriptions.dat"

    params_dict = load_param_descriptions(nextflow_param_descriptions_path)

    assembly_fasta_filename = args.assembly_fasta_path.split("/")[-1]
    split_assembly_filename = assembly_fasta_filename.split(".")
    truncated_filename = ".".join(split_assembly_filename[0:len(split_assembly_filename) - 1])
    truncated_filename = "".join(x for x in truncated_filename if (x.isalnum() or x in "._-"))

    if args.assembly_title == "":
        args.assembly_title = truncated_filename

    if args.annotation_target_species_id == "":
        args.annotation_target_species_id = truncated_filename

    path_variables = ["assembly_fasta_path", "singularity_image_path", "gff_path", "rna_seq_fastq_1_path", "rna_seq_fastq_2_path", "orthomcl_references_folder", "ref_mitoch_fasta_path", "ref_apicoplast_fasta_path", "pipeline_run_folder", "reference_assembly_path", "reference_gff_path"]
    input_file_folders = list()

    with open(out_path, "w") as f:
        f.write("// Nextflow configuration file for Genome Decomposition Analysis pipeline\n")
        timestamp_str = datetime.now().strftime("%d-%b-%Y (%H:%M)")
        f.write("// Autogenerated from command line arguments on {}\n".format(timestamp_str))

        if args.singularity_image_path != "":
            f.write("// Singularity variables\n")
            f.write("process.container = \"{}\"\n".format(os.path.abspath(args.singularity_image_path)))
            f.write("singularity.enabled = true\n")
            f.write("singularity.autoMounts = true\n")
        else:
            args.singularity_image_path = "NA"

        for arg in vars(args):
            arg_value = getattr(args, arg)
            if arg != "version":
                if arg_value != "NA":
                    if arg.endswith("_path") or arg in path_variables:
                        arg_value = os.path.abspath(arg_value)
                        input_file_folder = os.path.dirname(arg_value)
                        if input_file_folder not in input_file_folders:
                            input_file_folders.append(input_file_folder)

                param_name = "params." + str(arg)
                if param_name == "params.diamond_not_sensitive":
                    param_name = "params.diamond_sensitive"
                    if arg_value == False:
                        arg_value = True
                    else:
                        arg_value = False

                if param_name != "params.func":
                    param_description = None
                    param_type = None
                    if param_name in params_dict:
                        param_description = params_dict[param_name]["description"]
                        param_type = params_dict[param_name]["type"]
                    else:
                        sys.stderr.write("Parameter {} not found in the gda_nextflow_param_descriptions.dat file\n".format(param_name))
                        sys.exit(1)

                    if param_type != "int" and param_type != "bool":
                        arg_value = "\"" + arg_value + "\""
                    if param_type == "bool":
                        arg_value = str(arg_value).lower()
                    f.write("// {}\n".format(param_description))
                    f.write("{} = {}\n".format(param_name, arg_value))
        if args.singularity_image_path != "NA":
            f.write("// Singularity bind paths\n")
            f.write("singularity.runOptions = \"--bind {}\"\n".format(",".join(input_file_folders)))
        f.write("\ntrace {\nenabled = true\nfields = 'process,task_id,hash,name,attempt,status,exit,realtime,%cpu,vmem,rss,submit,start,complete,duration,realtime,rchar,wchar'\nfile = \"nextflow_trace.txt\"\n}\n")
    sys.stderr.write("Wrote a config file for Nextflow to the following path: {}\n".format(out_path))


def get_nextflow_script_path():
    """
    Returns the path to the GDA Nextflow script
    """
    nextflow_script_path = os.path.dirname(os.path.realpath(__file__)) + "/run_gda_feature_extraction_pipeline.nf"
    gpf.check_if_file_exists(nextflow_script_path)
    return nextflow_script_path


def check_if_executable_is_in_path(executable_name):
    """
    Checks if a script or binary that is needed is in path. Exits if it's not found
    """
    if which(executable_name) == None:
        sys.stderr.write("Error: the executable file '{}' is required but was not found in path\n".format(executable_name))
        sys.exit(1)


def extract_genomic_features(args):
    """
    Runs the pipeline for extracting genomic features (e.g. GC%, tandem repeat density, stop codon frequency etc) from the genome assembly
    """
    check_if_executable_is_in_path("nextflow")
    timestamp_str = datetime.now().strftime("%d-%b-%Y (%H:%M)")
    version_file_path = feature_extraction_scripts_path + "/version.dat"
    version_nr = gpf.l(version_file_path)[0]

    if args.custom_telomeric_seq != "NA":
        validate_custom_telomeric_seq(args.custom_telomeric_seq)

    if args.run_gene_annotation_pipeline == True and args.augustus_species == "NA":
        sys.stderr.write("Cannot start the gene annotation pipeline because no species model for Augustus has been selected. The species model for Augustus can be selected using the --augustus_species option\n")
        sys.exit(1)

    sys.stderr.write("Starting GDA genomic feature extraction pipeline version {} run at {}\n".format(version_nr, timestamp_str))
    if "CONDA_PREFIX" in os.environ:
        conda_env_name = os.environ["CONDA_PREFIX"]
        sys.stderr.write("conda environment: " + conda_env_name + "\n")
    
    if args.pipeline_run_folder == "" and args.pipeline_run_folder != "NA":
        args.pipeline_run_folder = assign_pipeline_run_folder_name()
    else:
        args.pipeline_run_folder = os.path.abspath(args.pipeline_run_folder)
    gpf.run_system_command("mkdir -p " + args.pipeline_run_folder)
    nextflow_config_outpath = args.pipeline_run_folder + "/nextflow.config"
    write_nextflow_config_file(args, nextflow_config_outpath)
    
    nextflow_script_path = get_nextflow_script_path()

    nextflow_command = "nextflow -C {} run {}".format(nextflow_config_outpath, nextflow_script_path)
    if args.singularity_image_path != "" and args.singularity_image_path != "NA":
        check_if_executable_is_in_path("singularity")
        nextflow_command += " -with-singularity {}".format(os.path.abspath(args.singularity_image_path))
    
    os.chdir(args.pipeline_run_folder)
    gpf.run_system_command(nextflow_command)
    timestamp_str = datetime.now().strftime("%d-%b-%Y (%H:%M)")
    sys.stderr.write("Exiting GDA genomic feature extraction pipeline at {}\n".format(timestamp_str))


def resume_genomic_feature_extraction(args):
    """
    Tries to resume a previously interrupted run of the Nextflow pipeline for extracting genomic features, using Nextflow's -resume flag
    """
    nextflow_script_path = get_nextflow_script_path()
    check_if_executable_is_in_path("nextflow")
    nextflow_config_full_path = os.path.abspath(args.nextflow_config_path)
    nextflow_command = "nextflow -C {} run {}".format(args.nextflow_config_path, nextflow_script_path)
    if args.singularity_image_path != "" and args.singularity_image_path != "NA":
        check_if_executable_is_in_path("singularity")
        nextflow_command += " -with-singularity {}".format(os.path.abspath(args.singularity_image_path))
    nextflow_command += " -resume"
    if args.run_name != "":
        nextflow_command += " " + args.run_name
    pipeline_run_folder = os.path.dirname(nextflow_config_full_path)
    os.chdir(pipeline_run_folder)
    gpf.run_system_command(nextflow_command)


def get_singularity_bind_command(bind_folders_list, singularity_image_path):
    """
    If a path to a Singularity image is defined, creates a string with that defines Singularity bind paths.
    This is to use it as the first part of a system command.
    If no Singularity image used, returns an empty string 
    """
    singularity_command = ""
    if singularity_image_path != "" and singularity_image_path != "NA":
        current_script_folder = os.path.dirname(os.path.realpath(__file__))
        full_singularity_image_path = os.path.abspath(singularity_image_path)
        check_if_executable_is_in_path("singularity")
        bind_folders_list.append(current_script_folder)
        bind_string = ""
        if len(bind_folders_list) > 0:
            for folder in bind_folders_list:
                bind_string += " --bind " + os.path.abspath(folder)
        singularity_command = "singularity exec{} {} ".format(bind_string, full_singularity_image_path)
    return singularity_command


def merge_bedgraph_files(args):
    """
    Takes bedgraph files with a fixed step size and merges them into a TSV table
    """
    if args.chunk_size < 1:
        sys.stderr.write("Invalid value for chunk_size ({}). This value cannot be smaller than 1\n".format(str(args.downsampling_factor)))
        sys.exit(1)
    include_repeat_family_tracks_flag = "false"
    if args.include_repeat_family_tracks == True:
        include_repeat_family_tracks_flag = "true"

    check_if_executable_is_in_path("merge_bedgraph_files")
    singularity_command = get_singularity_bind_command([os.path.dirname(args.assembly_fasta_path), os.path.abspath(args.bedgraph_folder)], args.singularity_image_path)
    merge_bedgraph_files_command = singularity_command + "merge_bedgraph_files {} {} {} {} {}".format(args.assembly_fasta_path, args.bedgraph_folder, args.chunk_size, args.assembly_title, include_repeat_family_tracks_flag)
    gpf.run_system_command(merge_bedgraph_files_command)


def downsample_merged_tsv(args):
    """
    Runs the code for downsampling the TSV file that has been produced by merging bedgraph files
    """
    gpf.check_if_file_exists(args.merged_tsv_path)
    if args.downsampling_factor < 1:
        sys.stderr.write("Invalid value for the downsampling factor ({}). This value cannot be smaller than 1\n".format(args.downsampling_factor))
        sys.exit(1)
    check_if_executable_is_in_path("downsample_merged_bedgraph_file")

    singularity_command = get_singularity_bind_command([os.path.dirname(args.merged_tsv_path)], args.singularity_image_path)
    downsampling_command = singularity_command + "downsample_merged_bedgraph_file {} {}".format(args.merged_tsv_path, args.downsampling_factor)
    gpf.run_system_command(downsampling_command)


def clustering_params(args):
    """
    Parameter selection for UMAP + HDBSCAN clustering of the windowed tracks
    """
    current_script_folder = os.path.dirname(os.path.realpath(__file__))
    check_if_executable_is_in_path(current_script_folder + "/gda_parameters.py")
    min_samples_string = ""
    if args.min_samples is not None:
        min_samples_string = " --min_samples " + str(args.min_samples)
    selected_scaff_only_string = ""
    if args.selected_scaff_only is not None:
         selected_scaff_only_string = " --selected_scaff_only " + str(args.selected_scaff_only)
    
    singularity_command = get_singularity_bind_command([args.tracks, args.directory], args.singularity_image_path)
    gda_params_command = singularity_command + "{}/gda_parameters.py -n {} -c {} -d {} --leaf_size {}{}{} {}".format(current_script_folder, args.n_neighbors, args.cluster_size_cutoff, args.directory, args.leaf_size, min_samples_string, selected_scaff_only_string, args.tracks)
        
    gpf.run_system_command("mkdir -p " + args.directory)
    gpf.run_system_command(gda_params_command)


def clustering(args):
    """
    Turning GDA genomic feature tracks into analysed clusters
    """
    current_script_folder = os.path.dirname(os.path.realpath(__file__))
    check_if_executable_is_in_path(current_script_folder + "/gda_clustering.py")
    min_samples_string = ""
    if args.min_samples is not None:
        min_samples_string = " --min_samples " + str(args.min_samples)
    singularity_command = get_singularity_bind_command([args.tracks, args.directory], args.singularity_image_path)

    gda_clustering_command = singularity_command + "{}/gda_clustering.py -n {} -c {} -p {} -w {} -d {} --leaf_size {}{} {}".format(current_script_folder, args.n_neighbors, args.cluster_size_cutoff, args.pvalue_cutoff, args.cluster_position_histogram_window_number, args.directory, args.leaf_size, min_samples_string, args.tracks)
    gpf.run_system_command("mkdir -p " + args.directory)
    gpf.run_system_command(gda_clustering_command)


def display_version(args):
    """
    Displays the version number of the GDA pipeline
    """
    for arg in vars(args):
        arg_value = getattr(args, arg)
        if arg == "version" and arg_value == True:
            version_file_path = feature_extraction_scripts_path + "/version.dat"
            version_nr = gpf.l(version_file_path)[0]
            print("GDA version " + version_nr)
        
    

def main():
    parser = argparse.ArgumentParser(description=__doc__)
    subparsers = parser.add_subparsers()

    parser_extract_genomic_features = subparsers.add_parser("extract_genomic_features", description=extract_genomic_features.__doc__)
    parser_extract_genomic_features.add_argument("assembly_fasta_path", type=str, help="Path to input assembly FASTA file")
    parser_extract_genomic_features.add_argument("--assembly_title", type=str, help="Assembly title (e.g. 'E. maxima'), used in plot titles (default: the basename of the assembly FASTA file)", default="")
    parser_extract_genomic_features.add_argument("--chunk_size", type=int, help="Genome chunk size (bp) for generating the bedgraph file using sliding window. Default: 5000", default=5000)
    parser_extract_genomic_features.add_argument("--threads", type=int, help="Number of CPU threads. Default: 1", default=1)
    parser_extract_genomic_features.add_argument("--pipeline_run_folder", type=str, help="Folder for running the pipeline. Default: automatically named new subfolder in the current working directory", default="")
    parser_extract_genomic_features.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_extract_genomic_features.add_argument("--ref_mitoch_fasta_path", type=str, help="Optional: path to FASTA file with reference mitochondrion sequence", default="NA")
    parser_extract_genomic_features.add_argument("--ref_apicoplast_fasta_path", type=str, help="Optional: path to FASTA file with reference apicoplast sequence", default="NA")
    parser_extract_genomic_features.add_argument("--gff_path", type=str, help="Optional: path to genome annotations GFF file", default="NA")
    parser_extract_genomic_features.add_argument("--rna_seq_fastq_1_path", type=str, help="Optional: Path to read 1 fastq.gz file of RNA-Seq paired end reads", default="NA")
    parser_extract_genomic_features.add_argument("--rna_seq_fastq_2_path", type=str, help="Optional: Path to read 2 fastq.gz file of RNA-Seq paired end reads", default="NA")
    parser_extract_genomic_features.add_argument("--orthomcl_references_folder", type=str, help="Optional: folder for reference proteomes for OrthoMCL", default="NA")
    parser_extract_genomic_features.add_argument("--diamond_memory_limit", type=int, help="Memory limit for Diamond (in gigabytes, default: 5)", default=5)
    parser_extract_genomic_features.add_argument("--diamond_not_sensitive", dest="diamond_not_sensitive", action="store_true", help="Running Diamond for OrthoMCL without the --sensitive flag (default: False)")
    parser_extract_genomic_features.set_defaults(diamond_not_sensitive=False)
    parser_extract_genomic_features.add_argument("--telomeric_seq_preset", type=str, help="Telomeric sequence type preset (default: vertebrates)", default="vertebrates", choices=["vertebrates", "paramecium", "apicomplexan", "oxytricha", "arabidopsis_thaliana", "cestrum_elegans", "allium", "zostera_marina", "green_algae", "insects", "roundworms", "saccharomyces_cerevisiae", "saccharomyces_castellii", "candida_glabrata", "candida_albicans", "candida_tropicalis", "candida_maltosa", "candida_guillermondii", "candida_pseudotropicalis", "kluyveromyces_lactis", "schizosaccharomyces_pombe", "dictyostelium" "tetrahymena"])
    parser_extract_genomic_features.add_argument("--custom_telomeric_seq", type=str, help="Optional: telomeric sequence(s) as a comma separated string, e.g. 'TTAGGGT,TTAGGGC'. If a sequence is entered here, it overrides the telomeric sequence type preset. Default: NA", default="NA")
    parser_extract_genomic_features.add_argument("--rf_stranded", dest="rf_stranded", action="store_true", help="Boolean argument for strandedness in the mapping of RNA-Seq reads. If this flag is enabled, HISAT2 is run with --rna-strandness RF flag. Otherwise the reads are mapped as unstranded")
    parser_extract_genomic_features.add_argument("--wgsim_target_coverage", type=int, help="Average coverage of WGSIM simulated reads (default: 10)", default=10)
    parser_extract_genomic_features.add_argument("--custom_gff_tags", type=str, help="Optional: comma separated string of custom tags for features to extract from the annotations GFF (example: five_prime_UTR,three_prime_UTR,miRNA)", default="")
    parser_extract_genomic_features.add_argument("--run_gene_annotation_pipeline", dest="run_gene_annotation_pipeline", action="store_true", help="Boolean argument that determines whether to run the gene annotation pipeline. Do not use this if your input genome is already annotated")
    parser_extract_genomic_features.add_argument("--annotation_target_species_id", type=str, help="Annotation target species ID (will be used in gene IDs when annotating genes)", default="")
    parser_extract_genomic_features.add_argument("--augustus_species", type=str, help="Species setting for Augustus", choices=["pea_aphid", "aedes", "amphimedon", "ancylostoma_ceylanicum", "adorsata", "honeybee1", "arabidopsis", "aspergillus_fumigatus", "aspergillus_nidulans", "anidulans", "aspergillus_oryzae", "aspergillus_terreus", "bombus_impatiens1", "bombus_terrestris2", "botrytis_cinerea", "brugia", "b_pseudomallei", "caenorhabditis", "c_elegans_trsk", "elegans", "elephant_shark", "camponotus_floridanus", "candida_albicans", "candida_guilliermondii", "candida_tropicalis", "chaetomium_globosum", "chiloscyllium", "chlamy2011", "chlamydomonas", "chlorella", "ciona", "coccidioides_immitis", "coccidioides_immitis", "Conidiobolus_coronatus", "coprinus_cinereus", "coprinus_cinereus", "coprinus", "coprinus", "cryptococcus_neoformans_gattii", "cryptococcus_neoformans_neoformans_B", "cryptococcus", "culex", "zebrafish", "debaryomyces_hansenii", "fly", "fly_exp", "encephalitozoon_cuniculi_GB", "eremothecium_gossypii", "E_coli_K12", "fusarium_graminearum", "fusarium", "galdieria", "chicken", "heliconius_melpomene1", "histoplasma_capsulatum", "histoplasma", "human", "kluyveromyces_lactis", "laccaria_bicolor", "leishmania_tarentolae", "japaneselamprey", "lodderomyces_elongisporus", "magnaporthe_grisea", "mnemiopsis_leidyi", "nasonia", "nematostella_vectensis", "neurospora_crassa", "neurospora", "coyote_tobacco", "rice", "parasteatoda", "sealamprey", "phanerochaete_chrysosporium", "pchrysosporium", "pichia_stipitis", "pisaster", "pfalciparum", "pneumocystis", "rhincodon", "rhizopus_oryzae", "rhodnius", "saccharomyces_cerevisiae_rm11-1a_1", "saccharomyces_cerevisiae_S288C", "saccharomyces", "schistosoma", "schistosoma2", "schizosaccharomyces_pombe", "scyliorhinus", "tomato", "s_aureus", "s_pneumoniae", "strongylocentrotus_purpuratus", "sulfolobus_solfataricus", "tetrahymena", "cacao", "thermoanaerobacter_tengcongensis", "toxoplasma", "tribolium2012", "trichinella", "wheat", "ustilago_maydis", "ustilago", "verticillium_albo_atrum1", "verticillium_longisporum1", "volvox", "Xipophorus_maculatus", "yarrowia_lipolytica", "maize", "maize5"], default="NA")
    parser_extract_genomic_features.add_argument("--augustus_chunk_overlap", type=int, help="Augustus chunk overlap (in basepairs, default: 12500)", default=12500)
    parser_extract_genomic_features.add_argument("--augustus_chunk_size", type=int, help="Augustus chunk size (in basepairs, default: 750000)", default=750000)
    parser_extract_genomic_features.add_argument("--reference_assembly_path", type=str, help="Optional: path to reference assembly for Liftoff", default="NA")
    parser_extract_genomic_features.add_argument("--reference_gff_path", type=str, help="Optional: path to reference GFF file for Liftoff", default="NA")
    parser_extract_genomic_features.add_argument("--barrnap_kingdom", type=str, help="Super kingdom of the species for Barrnap. Options: 'bac' (bacteria), 'arc' (archaea), 'euk' (eukaryota), 'mito': metazoan mitochondria. Default: 'euk'", choices=["bac", "arc", "euk", "mito"], default="euk")
    parser_extract_genomic_features.add_argument("--run_repeat_family_detection", dest="run_repeat_family_detection", action="store_true", help="Boolean that determines if repeat family detection is run (default: False)")
    parser_extract_genomic_features.add_argument("--repeat_family_detection_engine", dest="repeat_family_detection_engine", type=str, choices=["repeatmodeler", "meshclust2"], help="Software for detecting repeat families. Options: 'repeatmodeler', 'meshclust2'", default="repeatmodeler")
    parser_extract_genomic_features.add_argument("--include_gene_strand_bias", dest="include_gene_strand_bias", help="Boolean argument that determines whether a gene strand bias bedgraph track is produced (based on gene annotations GFF file)", action="store_true")
    parser_extract_genomic_features.add_argument("--skip_ltrharvest_ltrdigest", dest="skip_ltrharvest_ltrdigest", help="Boolean flag that can be used to skip running the LTRharvest and LTRdigest steps of the pipeline", action="store_true")
    parser_extract_genomic_features.add_argument("--feature_extraction_only", dest="feature_extraction_only", help="Boolean flag that can be used to skip running clustering after running the genomic feature extraction pipeline", action="store_true")
    parser_extract_genomic_features.set_defaults(func=extract_genomic_features)

    parser_resume_genomic_feature_extraction = subparsers.add_parser("resume_genomic_feature_extraction", description=resume_genomic_feature_extraction.__doc__)
    parser_resume_genomic_feature_extraction.add_argument("nextflow_config_path", type=str, help="Path to the Nextflow config file of the interrupted run (the standard file name for this is 'nextflow.config')")
    parser_resume_genomic_feature_extraction.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_resume_genomic_feature_extraction.add_argument("--run_name", type=str, help="Nextflow run name of the interrupted run (these are autogenerated by Nextflow and are reported in run logs, e.g. 'intergalactic_hypatia')", default="")
    parser_resume_genomic_feature_extraction.set_defaults(func=resume_genomic_feature_extraction)

    parser_merge_bedgraph_files = subparsers.add_parser("merge_bedgraph_files", description=merge_bedgraph_files.__doc__)
    parser_merge_bedgraph_files.add_argument("assembly_fasta_path", type=str, help="Path to the FASTA file of the assembly that corresponds to the bedgraph files")
    parser_merge_bedgraph_files.add_argument("bedgraph_folder", type=str, help="Path to folder with bedgraph files")
    parser_merge_bedgraph_files.add_argument("chunk_size", type=int, help="Genome chunk length (bp) of sliding window (default: 5000)", default=5000)
    parser_merge_bedgraph_files.add_argument("assembly_title", type=str, help="Species name for the assembly")
    parser_merge_bedgraph_files.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_merge_bedgraph_files.add_argument("--include_repeat_family_tracks", dest="include_repeat_family_tracks", action="store_true", help="If this option is enabled and the folder of bedgraph files contains subfolders called 'complex_repeats_bedgraph' and 'simple_repeats_bedgraph', the bedgraph files in these subfolders will be read too")
    parser_merge_bedgraph_files.set_defaults(func=merge_bedgraph_files)

    parser_downsample_merged_tsv = subparsers.add_parser("downsample_merged_tsv", description=downsample_merged_tsv.__doc__)
    parser_downsample_merged_tsv.add_argument("merged_tsv_path", type=str, help="Path to the TSV file that has been produced from merging bedgraph files of genomic feature tracks")
    parser_downsample_merged_tsv.add_argument("downsampling_factor", type=int, help="Downsampling factor. This number determines how many rows in the input file will be averaged into one row in the output file. For example, if the input has been generated with a window size 5 kb and desired window size in the output file is 20 kb, the value of the downsampling factor should be 4")
    parser_downsample_merged_tsv.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_downsample_merged_tsv.set_defaults(func=downsample_merged_tsv)

    parser_clustering_params = subparsers.add_parser("clustering_params", description=clustering_params.__doc__)
    parser_clustering_params.add_argument("-n", "--n_neighbors", help="N neighbours argument for UMAP [5,10,15,20]", default="5,10,15,20", type=str)
    parser_clustering_params.add_argument("-c", "--cluster_size_cutoff", help="HDBSCAN min cluster size [50,100,200,500]", default="50,100,200,500", type=str)
    parser_clustering_params.add_argument("-d", "--directory", help="Output dir [gda_out]", default="gda_out", type=str)
    parser_clustering_params.add_argument("--leaf_size", help="leaf_size setting for HDBSCAN (default: 40)", default=40, type=int)
    parser_clustering_params.add_argument("--min_samples", help="min_samples setting for HDBSCAN (default: None)", default=None, type=int)
    parser_clustering_params.add_argument("--selected_scaff_only", help="Optional: name of a scaffold from the input TSV file, to run UMAP+HDBSCAN with that scaffold only. Default: None (all scaffold are used by default)", default=None, type=str)
    parser_clustering_params.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_clustering_params.add_argument("tracks", help="File of windowed GDA tracks", type=str)
    parser_clustering_params.set_defaults(func=clustering_params)


    parser_clustering = subparsers.add_parser("clustering", description=clustering.__doc__)
    parser_clustering.add_argument("-n", "--n_neighbors", help="N neighbours argument for UMAP [13]", default=13, type=int)
    parser_clustering.add_argument("-c", "--cluster_size_cutoff", help="HDBSCAN min cluster size [200]", default=200, type=int)
    parser_clustering.add_argument("-p", "--pvalue_cutoff", help="p-value cutoff for feature enrichment in clusters [1e-20]", default=1e-20, type=float)
    parser_clustering.add_argument("-w", "--cluster_position_histogram_window_number", help="Cluster position histogram window number", default=20, type=float)
    parser_clustering.add_argument("-d", "--directory", help="Output dir [gda_out]", default="gda_out", type=str)
    parser_clustering.add_argument("--leaf_size", help="leaf_size setting for HDBSCAN (default: 40)", default=40, type=int)
    parser_clustering.add_argument("--min_samples", help="min_samples setting for HDBSCAN (default: None)", default=None, type=int)
    parser_clustering.add_argument("--singularity_image_path", type=str, help="Optional: path to Singularity image for loading the software dependencies for running the genomic feature extraction pipeline of GDA", default="")
    parser_clustering.add_argument("tracks", help="File of windowed GDA tracks", type=str)
    parser_clustering.set_defaults(func=clustering)

    parser.add_argument("--version", dest="version", action="store_true", help="Display the version number of this software")
    parser.set_defaults(func=display_version)
    
    args = parser.parse_args()
    if not len(sys.argv) > 1:
        parser.print_help()
        sys.exit(0)

    try:
        func = args.func
    except AttributeError:
        parser.error("too few arguments")
    func(args)
    

if __name__ == "__main__":
    main()